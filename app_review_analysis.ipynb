{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App Review Analysis\n",
    "\n",
    "# This notebook performs:\n",
    "# 1. App review scraping\n",
    "# 2. Sentiment analysis and visualization\n",
    "# 3. Categorization of reviews and frequency visualization\n",
    "# 4. Word cloud generation for frequent word analysis\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# Step 1: Install Required Libraries\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# Install the necessary libraries for scraping, sentiment analysis, categorization, and visualization.\n",
    "# You only need to run this once if these libraries are not already installed.\n",
    "\n",
    "!pip install app-store-scraper pandas torch transformers matplotlib requests seaborn wordcloud scikit-learn\n",
    "!pip install openai==0.28\n",
    "!pip install --upgrade urllib3 six\n",
    "# ------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: App Review Scraping\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from app_store_scraper import AppStore\n",
    "import time\n",
    "\n",
    "# Scraping app reviews from the Apple App Store\n",
    "def scrape_reviews(app_name, app_id, total_reviews, batch_size=100):\n",
    "    app = AppStore(country=\"us\", app_name=app_name, app_id=app_id)\n",
    "    all_reviews = []\n",
    "    total_fetched = 0\n",
    "    \n",
    "    while total_fetched < total_reviews:\n",
    "        app.review(how_many=batch_size)\n",
    "        if not app.reviews:\n",
    "            break\n",
    "        all_reviews.extend(app.reviews)\n",
    "        total_fetched += len(app.reviews)\n",
    "        print(f\"Fetched {len(app.reviews)} reviews, total so far: {total_fetched}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Convert datetime fields to strings\n",
    "    for review in all_reviews:\n",
    "        if isinstance(review['date'], datetime):\n",
    "            review['date'] = review['date'].isoformat()\n",
    "\n",
    "    return pd.DataFrame(all_reviews)\n",
    "\n",
    "# Scrape reviews and save to CSV\n",
    "df_reviews = scrape_reviews(\"tuya-smart\", 1034649547, total_reviews=200)\n",
    "df_reviews.to_csv('tuya_reviews_200.csv', index=False)\n",
    "print(f\"Saved {len(df_reviews)} reviews to 'tuya_reviews_200.csv' as a DataFrame.\")\n",
    "\n",
    "# ------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Sentiment Analysis and Visualization\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sentiment analysis using a pre-fine-tuned DistilBERT model\n",
    "def perform_sentiment_analysis(df):\n",
    "    sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "    \n",
    "    def get_sentiment(review_text):\n",
    "        result = sentiment_analysis(review_text)[0]\n",
    "        return result['label'], result['score']\n",
    "    \n",
    "    df[['sentiment', 'sentiment_score']] = df['review'].apply(lambda x: pd.Series(get_sentiment(x)))\n",
    "    return df\n",
    "\n",
    "# Visualize sentiment score and rating over time\n",
    "def visualize_sentiment_and_rating(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year_month'] = df['date'].dt.to_period('M')\n",
    "    rating_over_time = df.groupby('year_month').agg({'rating': 'mean', 'sentiment_score': 'mean'}).reset_index()\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "    \n",
    "    # Sentiment score plot\n",
    "    ax1.set_xlabel('Time (Year-Month)')\n",
    "    ax1.set_ylabel('Average Sentiment Score', color='blue')\n",
    "    ax1.plot(rating_over_time['year_month'].astype(str), rating_over_time['sentiment_score'], marker='o', color='blue', label='Sentiment Score')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax1.set_xticklabels(rating_over_time['year_month'].astype(str), rotation=45, ha='right')\n",
    "    \n",
    "    # Rating plot\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Average Rating', color='orange')\n",
    "    ax2.plot(rating_over_time['year_month'].astype(str), rating_over_time['rating'], marker='x', color='orange', label='Rating')\n",
    "    ax2.tick_params(axis='y', labelcolor='orange')\n",
    "    \n",
    "    plt.title('Sentiment Score and Rating Over Time')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Perform sentiment analysis and visualization\n",
    "df_reviews = perform_sentiment_analysis(pd.read_csv('tuya_reviews_200.csv'))\n",
    "visualize_sentiment_and_rating(df_reviews)\n",
    "\n",
    "# ------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Categorization and Visualization\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "import openai\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# Categorize app reviews using GPT-4\n",
    "import openai\n",
    "import time\n",
    "\n",
    "def categorize_reviews(df, batch_size=2):\n",
    "    openai_api_key = os.getenv(\"openai_api_key\")\n",
    "    openai.api_key = openai_api_key\n",
    "    prompt_template = \"\"\"\n",
    "    You are an AI designed to categorize app reviews based on both the title and content. The categories are:\n",
    "    - User Interface and Design\n",
    "    - Feature Requests\n",
    "    - Usability Issues\n",
    "    - App Stability and Reliability\n",
    "    - Performance Feedback\n",
    "    - Security and Privacy\n",
    "    - Notifications and Alerts\n",
    "    - Customer Support\n",
    "    - Subscription and Pricing\n",
    "    - Localization and Language Support\n",
    "    - Positive Feedback (Kudos)\n",
    "    Title: {title}\n",
    "    Review: {review}\n",
    "    Categories (comma-separated if more than one):\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_categories_in_batch(titles, reviews):\n",
    "        responses = []\n",
    "        for title, review in zip(titles, reviews):\n",
    "            prompt = prompt_template.format(title=title, review=review)\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    # Send the request to GPT-4\n",
    "                    response = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-4\",\n",
    "                        messages=[{\"role\": \"system\", \"content\": \"You are an AI designed to categorize app reviews.\"},\n",
    "                                  {\"role\": \"user\", \"content\": prompt}],\n",
    "                        max_tokens=100,\n",
    "                        temperature=0\n",
    "                    )\n",
    "                    categories = response['choices'][0]['message']['content'].strip()\n",
    "                    responses.append(categories.split(', '))\n",
    "                    break  # Exit the loop if successful\n",
    "                except openai.error.RateLimitError:\n",
    "                    # If rate limit is hit, wait before retrying\n",
    "                    print(\"Rate limit reached. Waiting 60 seconds before retrying...\")\n",
    "                    time.sleep(60)\n",
    "                except Exception as e:\n",
    "                    # Catch any other errors\n",
    "                    print(f\"Error: {e}\")\n",
    "                    time.sleep(10)\n",
    "        return responses\n",
    "\n",
    "    categories = []\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "        batch_categories = get_categories_in_batch(batch_df['title'].tolist(), batch_df['review'].tolist())\n",
    "        categories.extend(batch_categories)\n",
    "\n",
    "    df['category'] = categories\n",
    "    return df\n",
    "\n",
    "# Create binary columns for each category\n",
    "def create_binary_labels(df, all_categories):\n",
    "    for category in all_categories:\n",
    "        df[category] = df['category'].apply(lambda x: 1 if category in x else 0)\n",
    "    return df\n",
    "\n",
    "# Visualize category frequency\n",
    "def visualize_category_frequency(df, all_categories):\n",
    "    category_counts = df[all_categories].sum()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=category_counts.index, y=category_counts.values)\n",
    "    plt.title('Frequency of Each Category (Binary Labels)')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Perform categorization and visualization\n",
    "all_categories = [\n",
    "    'User Interface and Design', 'Feature Requests', 'Usability Issues',\n",
    "    'App Stability and Reliability', 'Performance Feedback', 'Security and Privacy',\n",
    "    'Notifications and Alerts', 'Customer Support', 'Subscription and Pricing',\n",
    "    'Localization and Language Support', 'Positive Feedback (Kudos)'\n",
    "]\n",
    "df_reviews = categorize_reviews(df_reviews)\n",
    "df_reviews = create_binary_labels(df_reviews, all_categories)\n",
    "visualize_category_frequency(df_reviews, all_categories)\n",
    "\n",
    "# ------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Word Cloud Generation\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Generate word cloud from reviews\n",
    "def generate_word_cloud(df):\n",
    "    all_reviews_text = ' '.join(df['review'])\n",
    "    stopwords = set(ENGLISH_STOP_WORDS)\n",
    "    custom_stopwords = {'app', 'review', 'feature', 'product', 'does', 'goes', 'thing'}\n",
    "    stopwords.update(custom_stopwords)\n",
    "    \n",
    "    wordcloud = WordCloud(\n",
    "        width=800, height=400, \n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=100,\n",
    "        colormap='viridis',\n",
    "        collocations=False\n",
    "    ).generate(all_reviews_text)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Generate word cloud\n",
    "generate_word_cloud(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
